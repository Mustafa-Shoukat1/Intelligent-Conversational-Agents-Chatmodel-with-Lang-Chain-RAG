{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbb77aac",
   "metadata": {
    "papermill": {
     "duration": 0.021624,
     "end_time": "2024-07-02T21:32:50.262014",
     "exception": false,
     "start_time": "2024-07-02T21:32:50.240390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"position: relative; text-align: center; background-image: url('https://th.bing.com/th/id/OIP.FhY2jL9E3OtyWAmmT_fFaAHaDt?w=341&h=175&c=7&r=0&o=5&dpr=1.5&pid=1.7'); background-size: cover; background-position: center; border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n",
    "    <div style=\"position: relative; z-index: 1; background-color: rgba(255, 255, 255, 0.9); backdrop-filter: blur(10px); border-radius: 20px; padding: 20px;\">\n",
    "        <h1 style=\"color: red; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.4); font-weight: bold; margin-bottom: 10px; font-size: 32px;\">Welcome!</h1>\n",
    "        <p style=\"color: #1976D2; font-size: 18px; margin: 10px 0;\">\n",
    "            I'm Mustafa Shoukat, a Generative Expert. I'm in the world of LLMs and exploring various concepts of Langchain and techniques to enhance my skills. In this notebook, I'll unlock the potential of Langchain, Langchain Prompting Techniques, and ChatModels.\n",
    "        </p>\n",
    "        <p style=\"color: #000000; font-size: 16px; font-style: italic; margin: 10px 0;\">\n",
    "            \"I am just a humble data practitioner. I make mistakes and I have blind spots. If you notice things I can improve or if you just want to chat, please feel free to DM me or connect :)\"\n",
    "        </p>\n",
    "        <p style=\"color: #2980B9; font-size: 16px; font-style: italic; margin: 10px 0;\">\n",
    "            <strong>About Notebook:</strong> 🧠 Integrating LangChain with HuggingFace and FAISS for Advanced NLP Applications\n",
    "        </p>\n",
    "        <p style=\"color: #27AE60; font-size: 16px; font-style: italic; margin: 10px 0;\">\n",
    "            This notebook explores building intelligent conversational agents with LangChain. It covers prompt engineering, chat model creation, document retrieval with FAISS, and text summarization using transformer models. Through practical examples, you'll learn to integrate these components into a context-aware chatbot system, providing a streamlined guide to developing advanced NLP applications.\n",
    "        </p>\n",
    "        <h2 style=\"color: red; margin-top: 15px; font-size: 28px;\">Contact Information</h2>\n",
    "        <table style=\"width: 100%; margin-top: 15px; border-collapse: collapse;\">\n",
    "            <tr style=\"background-color: #64B5F6; color: #ffffff;\">\n",
    "                <th style=\"padding: 8px; border-bottom: 2px solid #000000;\">Name</th>\n",
    "                <th style=\"padding: 8px; border-bottom: 2px solid #000000;\">Email</th>\n",
    "                <th style=\"padding: 8px; border-bottom: 2px solid #000000;\">LinkedIn</th>\n",
    "                <th style=\"padding: 8px; border-bottom: 2px solid #000000;\">GitHub</th>\n",
    "                <th style=\"padding: 8px; border-bottom: 2px solid #000000;\">Kaggle</th>\n",
    "            </tr>\n",
    "            <tr style=\"background-color: #FFFFFF; color: #000000;\">\n",
    "                <td style=\"padding: 8px;\">Mustafa Shoukat</td>\n",
    "                <td style=\"padding: 8px;\">mustafashoukat.ai@gmail.com</td>\n",
    "                <td style=\"padding: 8px;\">\n",
    "                    <a href=\"https://www.linkedin.com/in/mustafashoukat/\" target=\"_blank\">\n",
    "                        <img src=\"https://img.shields.io/badge/LinkedIn-0e76a8.svg?style=for-the-badge&logo=LinkedIn&logoColor=white\" alt=\"LinkedIn Badge\" style=\"border-radius: 5px; width: 100px;\">\n",
    "                    </a>\n",
    "                </td>\n",
    "                <td style=\"padding: 8px;\">\n",
    "                    <a href=\"https://github.com/Mustafa-Shoukat1\" target=\"_blank\">\n",
    "                        <img src=\"https://img.shields.io/badge/GitHub-171515.svg?style=for-the-badge&logo=GitHub&logoColor=white\" alt=\"GitHub Badge\" style=\"border-radius: 5px; width: 100px;\">\n",
    "                    </a>\n",
    "                </td>\n",
    "                <td style=\"padding: 8px;\">\n",
    "                    <a href=\"https://www.kaggle.com/mustafashoukat\" target=\"_blank\">\n",
    "                        <img src=\"https://img.shields.io/badge/Kaggle-20beff.svg?style=for-the-badge&logo=Kaggle&logoColor=white\" alt=\"Kaggle Badge\" style=\"border-radius: 5px; width: 100px;\">\n",
    "                    </a>\n",
    "                </td>\n",
    "            </tr>\n",
    "        </table>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- Optional image below the main content -->\n",
    "<img src=\"https://ralabs.org/wp-content/uploads/2024/04/Rectangle-2431.jpg\" alt=\"Optional Image\" style=\"width: 100%; height: auto; margin-top: 20px; border-radius: 10px;\">\n",
    " \n",
    "<div style=\"position: relative; text-align: center; background-image: url('https://th.bing.com/th/id/OIP.FhY2jL9E3OtyWAmmT_fFaAHaDt?w=341&h=175&c=7&r=0&o=5&dpr=1.5&pid=1.7'); background-size: cover; background-position: center; border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n",
    "    <div style=\"position: relative; z-index: 1; background-color: rgba(255, 255, 255, 0.9); backdrop-filter: blur(10px); border-radius: 20px; padding: 20px;\">\n",
    "        <p style=\"font-size: 16px; color: #000000;\">\n",
    "            Note: Include your API key in the sections where it is required. For instance, you might include your OpenAI API key or LangChain Hugging Face API key in the necessary code cells.\n",
    "        </p>\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3db860f",
   "metadata": {
    "papermill": {
     "duration": 0.021086,
     "end_time": "2024-07-02T21:32:50.304308",
     "exception": false,
     "start_time": "2024-07-02T21:32:50.283222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"position: relative; text-align: center; background-image: url('https://th.bing.com/th/id/OIP.FhY2jL9E3OtyWAmmT_fFaAHaDt?w=341&h=175&c=7&r=0&o=5&dpr=1.5&pid=1.7'); background-size: 50%; background-position: center; border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n",
    "    <div style=\"position: relative; z-index: 1; background-color: rgba(255, 255, 255, 0.9); backdrop-filter: blur(10px); border-radius: 20px; padding: 20px;\">\n",
    "       Installing Required Libraries\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20564a7e",
   "metadata": {
    "papermill": {
     "duration": 0.021221,
     "end_time": "2024-07-02T21:32:50.347118",
     "exception": false,
     "start_time": "2024-07-02T21:32:50.325897",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3f6ea9",
   "metadata": {
    "papermill": {
     "duration": 0.02085,
     "end_time": "2024-07-02T21:32:50.390064",
     "exception": false,
     "start_time": "2024-07-02T21:32:50.369214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e90f3b97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:32:50.434340Z",
     "iopub.status.busy": "2024-07-02T21:32:50.433851Z",
     "iopub.status.idle": "2024-07-02T21:33:39.193108Z",
     "shell.execute_reply": "2024-07-02T21:33:39.191895Z"
    },
    "papermill": {
     "duration": 48.784463,
     "end_time": "2024-07-02T21:33:39.195869",
     "exception": false,
     "start_time": "2024-07-02T21:32:50.411406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (4.12.2)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4) (2.5)\r\n",
      "Collecting langchain\r\n",
      "  Downloading langchain-0.2.6-py3-none-any.whl.metadata (7.0 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\r\n",
      "Collecting langchain-core<0.3.0,>=0.2.10 (from langchain)\r\n",
      "  Downloading langchain_core-0.2.10-py3-none-any.whl.metadata (6.0 kB)\r\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\r\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\r\n",
      "  Downloading langsmith-0.1.83-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (1.33)\r\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<0.3.0,>=0.2.10->langchain)\r\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\r\n",
      "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain) (2.4)\r\n",
      "Downloading langchain-0.2.6-py3-none-any.whl (975 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m975.5/975.5 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langchain_core-0.2.10-py3-none-any.whl (332 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.8/332.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\r\n",
      "Downloading langsmith-0.1.83-py3-none-any.whl (127 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.5/127.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: packaging, orjson, langsmith, langchain-core, langchain-text-splitters, langchain\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 21.3\r\n",
      "    Uninstalling packaging-21.3:\r\n",
      "      Successfully uninstalled packaging-21.3\r\n",
      "  Attempting uninstall: orjson\r\n",
      "    Found existing installation: orjson 3.9.10\r\n",
      "    Uninstalling orjson-3.9.10:\r\n",
      "      Successfully uninstalled orjson-3.9.10\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "keras-cv 0.9.0 requires keras-core, which is not installed.\r\n",
      "keras-nlp 0.12.1 requires keras-core, which is not installed.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\r\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\r\n",
      "jupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\r\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed langchain-0.2.6 langchain-core-0.2.10 langchain-text-splitters-0.2.2 langsmith-0.1.83 orjson-3.10.6 packaging-24.1\r\n",
      "Collecting openai\r\n",
      "  Downloading openai-1.35.8-py3-none-any.whl.metadata (21 kB)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.2.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.5.3)\r\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.0)\r\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai) (4.9.0)\r\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\r\n",
      "Downloading openai-1.35.8-py3-none-any.whl (328 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.1/328.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: openai\r\n",
      "Successfully installed openai-1.35.8\r\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install langchain\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa19d862",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:33:39.248237Z",
     "iopub.status.busy": "2024-07-02T21:33:39.247110Z",
     "iopub.status.idle": "2024-07-02T21:34:11.573593Z",
     "shell.execute_reply": "2024-07-02T21:34:11.572348Z"
    },
    "papermill": {
     "duration": 32.355423,
     "end_time": "2024-07-02T21:34:11.576389",
     "exception": false,
     "start_time": "2024-07-02T21:33:39.220966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.2.6)\r\n",
      "Requirement already satisfied: langchain-core in /opt/conda/lib/python3.10/site-packages (0.2.10)\r\n",
      "Collecting langchain-community\r\n",
      "  Downloading langchain_community-0.2.6-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting langchain-openai\r\n",
      "  Downloading langchain_openai-0.1.13-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\r\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.2)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.83)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core) (1.33)\r\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core) (24.1)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.6.6)\r\n",
      "Requirement already satisfied: openai<2.0.0,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from langchain-openai) (1.35.8)\r\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\r\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.2)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.4)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.2.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (0.27.0)\r\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.3.0)\r\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.9.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2023.12.25)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.2.0)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (0.14.0)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\r\n",
      "Downloading langchain_community-0.2.6-py3-none-any.whl (2.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langchain_openai-0.1.13-py3-none-any.whl (45 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tiktoken, langchain-openai, langchain-community\r\n",
      "Successfully installed langchain-community-0.2.6 langchain-openai-0.1.13 tiktoken-0.7.0\r\n",
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.2.6)\r\n",
      "Requirement already satisfied: langchain_community in /opt/conda/lib/python3.10/site-packages (0.2.6)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\r\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.10)\r\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.2)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.83)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.6.6)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.2)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (1.33)\r\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (24.1)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain) (2.4)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-core langchain-community langchain-openai\n",
    "\n",
    "!pip install langchain langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a143d4eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:34:11.633088Z",
     "iopub.status.busy": "2024-07-02T21:34:11.632709Z",
     "iopub.status.idle": "2024-07-02T21:34:11.637530Z",
     "shell.execute_reply": "2024-07-02T21:34:11.636537Z"
    },
    "papermill": {
     "duration": 0.035729,
     "end_time": "2024-07-02T21:34:11.639931",
     "exception": false,
     "start_time": "2024-07-02T21:34:11.604202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "\n",
    "# os.environ['HUGGINGFACEHUB_API_TOKEN'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85c0edae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:34:11.696291Z",
     "iopub.status.busy": "2024-07-02T21:34:11.695413Z",
     "iopub.status.idle": "2024-07-02T21:34:27.181349Z",
     "shell.execute_reply": "2024-07-02T21:34:27.179634Z"
    },
    "papermill": {
     "duration": 15.517425,
     "end_time": "2024-07-02T21:34:27.184267",
     "exception": false,
     "start_time": "2024-07-02T21:34:11.666842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.2.6)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\r\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.10)\r\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.2)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.83)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (1.33)\r\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (24.1)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain) (2.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "# prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "# print(prompt)\n",
    "\n",
    "\n",
    "# llm_chain = LLMChain(prompt=prompt, \n",
    "#                      llm=HuggingFaceHub(repo_id=\"google/flan-t5-xl\", \n",
    "#                                         model_kwargs={\"temperature\":0, \n",
    "#                                                       \"max_length\":64}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2675eb",
   "metadata": {
    "papermill": {
     "duration": 0.02774,
     "end_time": "2024-07-02T21:34:27.240148",
     "exception": false,
     "start_time": "2024-07-02T21:34:27.212408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"position: relative; text-align: center; background-image: url('https://th.bing.com/th/id/OIP.FhY2jL9E3OtyWAmmT_fFaAHaDt?w=341&h=175&c=7&r=0&o=5&dpr=1.5&pid=1.7'); background-size: 50%; background-position: center; border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n",
    "    <div style=\"position: relative; z-index: 1; background-color: rgba(255, 255, 255, 0.9); backdrop-filter: blur(10px); border-radius: 20px; padding: 20px;\">\n",
    "       🔗 LangChain | RAG \n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5297c205",
   "metadata": {
    "papermill": {
     "duration": 0.027566,
     "end_time": "2024-07-02T21:34:27.295566",
     "exception": false,
     "start_time": "2024-07-02T21:34:27.268000",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "LangChain is a framework for creating applications powered by large language models (LLMs). It simplifies the LLM application lifecycle with three main stages:\n",
    "\n",
    "## 1. Development\n",
    "- **Components**: 🛠️ Use open-source building blocks and integrations.\n",
    "- **LangGraph**: 🌐 Build stateful agents with streaming and human-in-the-loop features.\n",
    "\n",
    "## 2. Productionization\n",
    "- **LangSmith**: 🕵️‍♂️ Inspect, monitor, and evaluate your chains to optimize and ensure quality.\n",
    "\n",
    "## 3. Deployment\n",
    "- **LangGraph Cloud**: ☁️ Turn your applications into production-ready APIs and Assistants.\n",
    "\n",
    "## RAG 📚\n",
    "\n",
    "## Understanding RAG (Retrieval-Augmented Generation)\n",
    "\n",
    "### 1. **Basic RAG** 📄🔄📝\n",
    "- **What it does**: Combines retrieval of documents with generation of responses.\n",
    "- **How it works**: Uses a retriever to fetch relevant documents and a generator to produce text based on the retrieved information.\n",
    "\n",
    "### 2. **Advanced RAG**\n",
    "- **RAG-Token** 📝🔄\n",
    "  - **What it does**: Retrieves documents and generates responses token-by-token.\n",
    "  - **How it helps**: Allows for more refined and contextually accurate generation.\n",
    "- **RAG-Sequence** 📄➡️📝\n",
    "  - **What it does**: Retrieves documents first and then generates a full response in one go.\n",
    "  - **How it helps**: Focuses on generating longer, more coherent text.\n",
    "\n",
    "### 3. **RAFT (Retrieval-Augmented Fine-Tuning)** 🎯📈\n",
    "- **What it does**: A variant of RAG that fine-tunes a model by incorporating retrieval results directly into the training process.\n",
    "- **How it helps**: Enhances the model's ability to generate contextually relevant text.\n",
    "\n",
    "### 4. **Rafter** 🛠️✨\n",
    "- **What it means**: Often a term used to describe advanced or customized versions of RAG models.\n",
    "- **How it helps**: Provides additional features or optimizations for specific use cases.\n",
    "\n",
    "These variations and extensions aim to improve the effectiveness and efficiency of retrieval and generation in natural language processing tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f256cd98",
   "metadata": {
    "papermill": {
     "duration": 0.027288,
     "end_time": "2024-07-02T21:34:27.351833",
     "exception": false,
     "start_time": "2024-07-02T21:34:27.324545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "<div style=\"position: relative; text-align: center; background-image: url('https://th.bing.com/th/id/OIP.FhY2jL9E3OtyWAmmT_fFaAHaDt?w=341&h=175&c=7&r=0&o=5&dpr=1.5&pid=1.7'); background-size: 50%; background-position: center; border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n",
    "    <div style=\"position: relative; z-index: 1; background-color: rgba(255, 255, 255, 0.9); backdrop-filter: blur(10px); border-radius: 20px; padding: 20px;\">\n",
    "       Difference between LLMs and Chat Models 🤖💬\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ec86fd",
   "metadata": {
    "papermill": {
     "duration": 0.027478,
     "end_time": "2024-07-02T21:34:27.407402",
     "exception": false,
     "start_time": "2024-07-02T21:34:27.379924",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## **Large Language Models (LLMs):**<br><br>\n",
    "\n",
    "LLMs are like super-smart text generators. They're great at understanding language and can write coherent and relevant text for a wide range of tasks. For example, they can summarize articles, translate languages, or even write stories.\n",
    "\n",
    "**Focus:**\n",
    "\n",
    "They focus on generating text.<br><br>\n",
    "**How They Work:**<br><br>\n",
    "LLMs learn from huge amounts of text data to understand language patterns.<br><br>\n",
    "**Strengths:**<br><br>\n",
    "They're flexible and powerful at understanding and creating text.<br><br>\n",
    "Examples: GPT-4 is a famous example of a large language model.<br><br>\n",
    "\n",
    "\n",
    "## **Chat Models:**\n",
    "\n",
    "Chat Models are like conversational partners. <br><br>\n",
    "\n",
    "They're specifically designed to have interactive conversations with people. They aim to understand what you're saying and respond in a way that makes sense in a conversation.\n",
    "\n",
    "**Focus:** <br><br>\n",
    "\n",
    "They're all about interactive conversations.<br><br>\n",
    "**How They Work:**<br><br>\n",
    "\n",
    "Chat Models pay attention to both what's said before and after in a conversation to understand context better.<br><br>\n",
    "**Strengths:**<br><br>\n",
    "\n",
    "They're good at keeping track of what's been said before and making conversation feel natural.<br><br>\n",
    "Examples: OpenAI's ChatGPT is a well-known chat model.\n",
    "\n",
    "**system_fingerprint:**<br><br>\n",
    "\n",
    "This is a unique identifier or fingerprint associated with the specific system or environment where the request was processed. It helps OpenAI track and monitor the usage of their API across different systems. It's essentially a way to identify the system that generated the response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812c3a5f",
   "metadata": {
    "id": "wcboICg7SugD",
    "papermill": {
     "duration": 0.027241,
     "end_time": "2024-07-02T21:34:27.462342",
     "exception": false,
     "start_time": "2024-07-02T21:34:27.435101",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "<div style=\"position: relative; text-align: center; background-image: url('https://th.bing.com/th/id/OIP.FhY2jL9E3OtyWAmmT_fFaAHaDt?w=341&h=175&c=7&r=0&o=5&dpr=1.5&pid=1.7'); background-size: 50%; background-position: center; border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n",
    "    <div style=\"position: relative; z-index: 1; background-color: rgba(255, 255, 255, 0.9); backdrop-filter: blur(10px); border-radius: 20px; padding: 20px;\">\n",
    "       🔗 Runnable interface \n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "### [Runnable interface](https://python.langchain.com/docs/expression_language/interface/)\n",
    "\n",
    "(Why chain.invoke)\n",
    "\n",
    "To make it as easy as possible to create custom chains, we’ve implemented a “Runnable” protocol. Many LangChain components implement the Runnable protocol, including chat models, LLMs, output parsers, retrievers, prompt templates, and more. There are also several useful primitives for working with runnables, which you can read about in this section.\n",
    "\n",
    "This is a standard interface, which makes it easy to define custom chains as well as invoke them in a standard way.<br><br>\n",
    "\n",
    "The standard interface includes:\n",
    "\n",
    "**stream:**<br><br> stream back chunks of the response<br><br>\n",
    "**invoke:**<br><br> call the chain on an input<br><br>\n",
    "**batch:**<br><br> call the chain on a list of inputs<br><br>\n",
    "These also have corresponding async methods that should be used with asyncio await syntax for concurrency:\n",
    "\n",
    "**astream:**<br><br> stream back chunks of the response async<br><br>\n",
    "**ainvoke:**<br><br> call the chain on an input async<br><br>\n",
    "**abatch:**<br><br> call the chain on a list of inputs async<br><br>\n",
    "**astream_log:** <br><br>stream back intermediate steps as they happen, in addition to the final response<br><br>\n",
    "**astream_events:**<br><br> beta stream events as they happen in the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1642e31a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:34:27.520440Z",
     "iopub.status.busy": "2024-07-02T21:34:27.519907Z",
     "iopub.status.idle": "2024-07-02T21:34:27.524951Z",
     "shell.execute_reply": "2024-07-02T21:34:27.523942Z"
    },
    "id": "QDqbTUGaRMzL",
    "papermill": {
     "duration": 0.037195,
     "end_time": "2024-07-02T21:34:27.527122",
     "exception": false,
     "start_time": "2024-07-02T21:34:27.489927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# model = ChatOpenAI(openai_api_key=openai_key)\n",
    "# prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
    "\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# output_parser = StrOutputParser()\n",
    "# chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3fd122",
   "metadata": {
    "id": "Mdl3lz1dTLpz",
    "papermill": {
     "duration": 0.027743,
     "end_time": "2024-07-02T21:34:27.582682",
     "exception": false,
     "start_time": "2024-07-02T21:34:27.554939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Stream**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82cf1cea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:34:27.639999Z",
     "iopub.status.busy": "2024-07-02T21:34:27.639557Z",
     "iopub.status.idle": "2024-07-02T21:34:27.644140Z",
     "shell.execute_reply": "2024-07-02T21:34:27.643117Z"
    },
    "id": "L24cU5mfS20d",
    "outputId": "ea864fbc-789a-492a-812d-7ffac0286bb3",
    "papermill": {
     "duration": 0.035998,
     "end_time": "2024-07-02T21:34:27.646422",
     "exception": false,
     "start_time": "2024-07-02T21:34:27.610424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for s in chain.stream({\"topic\": \"bears\"}):\n",
    "#     print(s.content, end=\"\", flush=True)\n",
    "\n",
    "# Why do bears have hairy coats?\n",
    "\n",
    "# Because they don't like to shave!    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6f1754",
   "metadata": {
    "id": "YS7qmjnQTOSP",
    "papermill": {
     "duration": 0.027666,
     "end_time": "2024-07-02T21:34:27.701657",
     "exception": false,
     "start_time": "2024-07-02T21:34:27.673991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**invoke**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d63175e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:34:27.759269Z",
     "iopub.status.busy": "2024-07-02T21:34:27.758909Z",
     "iopub.status.idle": "2024-07-02T21:34:27.763673Z",
     "shell.execute_reply": "2024-07-02T21:34:27.762643Z"
    },
    "id": "iHezaF3MTQrL",
    "outputId": "9daed558-e0a7-4e06-b13f-235963626327",
    "papermill": {
     "duration": 0.03618,
     "end_time": "2024-07-02T21:34:27.765855",
     "exception": false,
     "start_time": "2024-07-02T21:34:27.729675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# chain.invoke({\"topic\": \"bears\"})\n",
    "\n",
    "# AIMessage(content='Why did the bear bring a flashlight to the party? \\n\\nBecause he heard it was going to be a \"beary\" bright time!', \n",
    "# response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 13, 'total_tokens': 41}, \n",
    "# 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'stop', 'logprobs': None},\n",
    "# id='run-a605d2f0-86be-491c-82b6-7f3052088700-0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defd9a9d",
   "metadata": {
    "id": "OnXcvTIQTWx9",
    "papermill": {
     "duration": 0.027597,
     "end_time": "2024-07-02T21:34:27.821398",
     "exception": false,
     "start_time": "2024-07-02T21:34:27.793801",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**batch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b934b17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:34:27.933058Z",
     "iopub.status.busy": "2024-07-02T21:34:27.932694Z",
     "iopub.status.idle": "2024-07-02T21:34:27.937121Z",
     "shell.execute_reply": "2024-07-02T21:34:27.936077Z"
    },
    "id": "GDsMfRV8TYwE",
    "outputId": "e8266db9-cb7e-4694-99de-fb848274679f",
    "papermill": {
     "duration": 0.090356,
     "end_time": "2024-07-02T21:34:27.939453",
     "exception": false,
     "start_time": "2024-07-02T21:34:27.849097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# chain.batch([{\"topic\": \"bears\"}, {\"topic\": \"cats\"}])\n",
    "\n",
    "# ['Why do bears have hairy coats?\\n \\nFur protection!',\n",
    "# , 'Why was the cat sitting on the computer?\\n\\nBecause it wanted to keep an eye on the mouse!']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8c0925",
   "metadata": {
    "id": "VUVE_WFdVIlg",
    "papermill": {
     "duration": 0.027672,
     "end_time": "2024-07-02T21:34:27.995903",
     "exception": false,
     "start_time": "2024-07-02T21:34:27.968231",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Async Stream**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f4b758e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:34:28.053980Z",
     "iopub.status.busy": "2024-07-02T21:34:28.053612Z",
     "iopub.status.idle": "2024-07-02T21:34:28.057810Z",
     "shell.execute_reply": "2024-07-02T21:34:28.056877Z"
    },
    "id": "fj8ERNkATq_n",
    "outputId": "4db170c4-6326-4ef6-da1e-9deda60e6857",
    "papermill": {
     "duration": 0.035688,
     "end_time": "2024-07-02T21:34:28.060186",
     "exception": false,
     "start_time": "2024-07-02T21:34:28.024498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# async for s in chain.astream({\"topic\": \"bears\"}):\n",
    "#     print(s.content, end=\"\", flush=True)\n",
    "    \n",
    "# Why did the bear go to the dentist? \n",
    "# To get a \"bear-y\" good checkup!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afb3182",
   "metadata": {
    "id": "lumiWe_SU8Qt",
    "papermill": {
     "duration": 0.028018,
     "end_time": "2024-07-02T21:34:28.116807",
     "exception": false,
     "start_time": "2024-07-02T21:34:28.088789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In programming terms, async for allows you to perform asynchronous iteration, meaning you can continue with other tasks while waiting for each iteration to complete, whereas for performs synchronous iteration, meaning it blocks until each iteration is finished before moving on to the next one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546dc8ce",
   "metadata": {
    "id": "m-gd_h5JVO0Y",
    "papermill": {
     "duration": 0.026985,
     "end_time": "2024-07-02T21:34:28.171270",
     "exception": false,
     "start_time": "2024-07-02T21:34:28.144285",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Async Invoke**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3efb9caf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:34:28.229958Z",
     "iopub.status.busy": "2024-07-02T21:34:28.229483Z",
     "iopub.status.idle": "2024-07-02T21:34:28.234077Z",
     "shell.execute_reply": "2024-07-02T21:34:28.233044Z"
    },
    "id": "WMDC5HPiVTZQ",
    "papermill": {
     "duration": 0.035956,
     "end_time": "2024-07-02T21:34:28.236357",
     "exception": false,
     "start_time": "2024-07-02T21:34:28.200401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# await chain.ainvoke({\"topic\": \"bears\"})\n",
    "# ainvoke: Asynchronously executes a task, allowing other tasks to proceed without waiting for the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbbb036",
   "metadata": {
    "papermill": {
     "duration": 0.027164,
     "end_time": "2024-07-02T21:34:28.291337",
     "exception": false,
     "start_time": "2024-07-02T21:34:28.264173",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"position: relative; text-align: center; background-image: url('https://th.bing.com/th/id/OIP.FhY2jL9E3OtyWAmmT_fFaAHaDt?w=341&h=175&c=7&r=0&o=5&dpr=1.5&pid=1.7'); background-size: 50%; background-position: center; border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n",
    "    <div style=\"position: relative; z-index: 1; background-color: rgba(255, 255, 255, 0.9); backdrop-filter: blur(10px); border-radius: 20px; padding: 20px;\">\n",
    "       Prompt Template\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290043c0",
   "metadata": {
    "id": "N1U2fkhjS7DM",
    "papermill": {
     "duration": 0.027365,
     "end_time": "2024-07-02T21:34:28.346564",
     "exception": false,
     "start_time": "2024-07-02T21:34:28.319199",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A prompt template offers a standardized way to frame requests or tasks. By providing a specific format, it helps in organizing the input data (like a book description or a recipe) clearly and coherently. This structure is particularly beneficial for complex tasks, as it helps in breaking them down into more manageable components.\n",
    "\n",
    "The straightforward method to apply a prompt template is by using injections.\n",
    "\n",
    "\n",
    "    original_recipe = \"\"\"\n",
    "    This recipe details how to make a classic New York-style cheesecake.\n",
    "    It includes cream cheese, sour cream, sugar, and a graham cracker crust.\n",
    "    \"\"\"\n",
    "\n",
    "    dietary_preference = \"\"\"Vegan, using plant-based substitutes\"\"\"\n",
    "    difficulty_level = \"Simplified for beginners\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Modify the following {original_recipe} to suit a {dietary_preference} and\n",
    "    adjust it to a {difficulty_level} cooking level.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b63f4481",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:34:28.404083Z",
     "iopub.status.busy": "2024-07-02T21:34:28.403673Z",
     "iopub.status.idle": "2024-07-02T21:34:28.409136Z",
     "shell.execute_reply": "2024-07-02T21:34:28.408075Z"
    },
    "id": "9JMQUV3iW1wp",
    "papermill": {
     "duration": 0.036898,
     "end_time": "2024-07-02T21:34:28.411425",
     "exception": false,
     "start_time": "2024-07-02T21:34:28.374527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_recipe = \"\"\"\n",
    "This recipe details how to make a classic New York-style cheesecake.\n",
    "It includes cream cheese, sour cream, sugar, and a graham cracker crust.\n",
    "\"\"\"\n",
    "\n",
    "dietary_preference = \"\"\"Vegan, using plant-based substitutes\"\"\"\n",
    "difficulty_level = \"Simplified for beginners\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Modify the following {original_recipe} to suit a {dietary_preference} and\n",
    "adjust it to a {difficulty_level} cooking level.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b6c4bc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:34:28.469172Z",
     "iopub.status.busy": "2024-07-02T21:34:28.468788Z",
     "iopub.status.idle": "2024-07-02T21:34:28.476147Z",
     "shell.execute_reply": "2024-07-02T21:34:28.475124Z"
    },
    "id": "6ccjufL365sn",
    "outputId": "7ce51921-ea11-4536-ef3e-a827e892de0a",
    "papermill": {
     "duration": 0.039162,
     "end_time": "2024-07-02T21:34:28.478542",
     "exception": false,
     "start_time": "2024-07-02T21:34:28.439380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nModify the following \\nThis recipe details how to make a classic New York-style cheesecake.\\nIt includes cream cheese, sour cream, sugar, and a graham cracker crust.\\n to suit a Vegan, using plant-based substitutes and\\nadjust it to a Simplified for beginners cooking level.\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9a0dbc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:34:28.537617Z",
     "iopub.status.busy": "2024-07-02T21:34:28.537238Z",
     "iopub.status.idle": "2024-07-02T21:34:28.542463Z",
     "shell.execute_reply": "2024-07-02T21:34:28.541612Z"
    },
    "id": "hfJrW9zQWXrc",
    "outputId": "c97b9f47-b603-4975-bbf6-cf7e6a929987",
    "papermill": {
     "duration": 0.03745,
     "end_time": "2024-07-02T21:34:28.544787",
     "exception": false,
     "start_time": "2024-07-02T21:34:28.507337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
    "\n",
    "# from langchain.llms import OpenAI\n",
    "# llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "# print(llm(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19bebcc",
   "metadata": {
    "papermill": {
     "duration": 0.027631,
     "end_time": "2024-07-02T21:34:28.600060",
     "exception": false,
     "start_time": "2024-07-02T21:34:28.572429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"position: relative; text-align: center; background-image: url('https://th.bing.com/th/id/OIP.FhY2jL9E3OtyWAmmT_fFaAHaDt?w=341&h=175&c=7&r=0&o=5&dpr=1.5&pid=1.7'); background-size: 50%; background-position: center; border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n",
    "    <div style=\"position: relative; z-index: 1; background-color: rgba(255, 255, 255, 0.9); backdrop-filter: blur(10px); border-radius: 20px; padding: 20px;\">\n",
    "        Langchain Prompt Template\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1bfa9b",
   "metadata": {
    "id": "Zmx0VXgXXJwk",
    "papermill": {
     "duration": 0.027558,
     "end_time": "2024-07-02T21:34:28.655647",
     "exception": false,
     "start_time": "2024-07-02T21:34:28.628089",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "LangChain prompt templates streamline the process of creating and managing prompts, enhance the quality of interactions with language models, and provide a scalable, flexible, and error-resistant method for developing AI-powered applications.<br><br>\n",
    "PromptTemplate class is designed to construct structured prompts with placeholders for dynamic input, enhancing prompt management and reusability.<br><br>\n",
    "\n",
    "- Key Features:<br><br>\n",
    "\n",
    "**Placeholders:**<br><br> Use curly braces ({}) to designate variables within the prompt template, enabling flexible prompt generation.<br><br>\n",
    "**Input Variables:**<br><br> Explicitly define anticipated input variables for clarity and error prevention.<br><br>\n",
    "**Template String:**<br><br> Compose the core prompt structure, containing placeholders to be populated with actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd1a662a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:34:28.713559Z",
     "iopub.status.busy": "2024-07-02T21:34:28.713211Z",
     "iopub.status.idle": "2024-07-02T21:34:28.721608Z",
     "shell.execute_reply": "2024-07-02T21:34:28.720477Z"
    },
    "id": "VvpS74PRXvHR",
    "outputId": "2e4fcbff-51d3-4b67-9b16-b8def6fab753",
    "papermill": {
     "duration": 0.040037,
     "end_time": "2024-07-02T21:34:28.724037",
     "exception": false,
     "start_time": "2024-07-02T21:34:28.684000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['dietary_preference', 'difficulty_level', 'original_recipe'] template='Modify the following {original_recipe} to suit a {dietary_preference}\\nand adjust it to a {difficulty_level} cooking level.'\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"Modify the following {original_recipe} to suit a {dietary_preference}\n",
    "and adjust it to a {difficulty_level} cooking level.\"\"\"\n",
    ")\n",
    "prompt = prompt_template.format(original_recipe=\"This recipe details how to make a classic New York-style cheesecake. It includes cream cheese, sour cream, sugar, and a graham cracker crust.\",\n",
    "                       dietary_preference=\"Vegan, using plant-based substitutes\",\n",
    "                       difficulty_level=\"Simplified for beginners\")\n",
    "\n",
    "\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5c10ed2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:34:28.782620Z",
     "iopub.status.busy": "2024-07-02T21:34:28.781850Z",
     "iopub.status.idle": "2024-07-02T21:34:28.788233Z",
     "shell.execute_reply": "2024-07-02T21:34:28.787242Z"
    },
    "id": "SJ0R9br-X0PW",
    "outputId": "71fe19c6-2344-4817-a6ae-644e97dc75f0",
    "papermill": {
     "duration": 0.037986,
     "end_time": "2024-07-02T21:34:28.790415",
     "exception": false,
     "start_time": "2024-07-02T21:34:28.752429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Modify the following This recipe details how to make a classic New York-style cheesecake. It includes cream cheese, sour cream, sugar, and a graham cracker crust. to suit a Vegan, using plant-based substitutes\\nand adjust it to a Simplified for beginners cooking level.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36c3c345",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:34:28.849779Z",
     "iopub.status.busy": "2024-07-02T21:34:28.848838Z",
     "iopub.status.idle": "2024-07-02T21:34:28.853327Z",
     "shell.execute_reply": "2024-07-02T21:34:28.852333Z"
    },
    "id": "dmLHgwFlYC9f",
    "papermill": {
     "duration": 0.036268,
     "end_time": "2024-07-02T21:34:28.855447",
     "exception": false,
     "start_time": "2024-07-02T21:34:28.819179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# response = llm(prompt)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94de9453",
   "metadata": {
    "papermill": {
     "duration": 0.027712,
     "end_time": "2024-07-02T21:34:28.911219",
     "exception": false,
     "start_time": "2024-07-02T21:34:28.883507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"position: relative; text-align: center; background-image: url('https://th.bing.com/th/id/OIP.FhY2jL9E3OtyWAmmT_fFaAHaDt?w=341&h=175&c=7&r=0&o=5&dpr=1.5&pid=1.7'); background-size: 50%; background-position: center; border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n",
    "    <div style=\"position: relative; z-index: 1; background-color: rgba(255, 255, 255, 0.9); backdrop-filter: blur(10px); border-radius: 20px; padding: 20px;\">\n",
    "        Langchain ChatPromptTemplate\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6861e2f6",
   "metadata": {
    "id": "bIcmcrHIYJR4",
    "papermill": {
     "duration": 0.0281,
     "end_time": "2024-07-02T21:34:28.967259",
     "exception": false,
     "start_time": "2024-07-02T21:34:28.939159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ChatPromptTemplate is designed to create structured prompts specifically for chat-based interactions with language models. It enables us to model conversations, including context and turn-taking, leading to more coherent and engaging responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5823dc04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:34:29.025468Z",
     "iopub.status.busy": "2024-07-02T21:34:29.025075Z",
     "iopub.status.idle": "2024-07-02T21:34:29.035119Z",
     "shell.execute_reply": "2024-07-02T21:34:29.034134Z"
    },
    "id": "w-bJgtaMYe20",
    "outputId": "92b128ba-6249-47f7-a97d-3080e2059709",
    "papermill": {
     "duration": 0.041732,
     "end_time": "2024-07-02T21:34:29.037282",
     "exception": false,
     "start_time": "2024-07-02T21:34:28.995550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a knowledgeable travel advisor AI. You provide useful travel tips.'),\n",
       " HumanMessage(content=\"Hi, I'm planning a trip and need some advice.\"),\n",
       " AIMessage(content=\"Sure, I'd be happy to help! What's your destination?\"),\n",
       " HumanMessage(content='Paris'),\n",
       " AIMessage(content='Great choice! I have some tips for Paris.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a knowledgeable travel advisor AI. You provide useful travel tips.\"),\n",
    "        (\"human\", \"Hi, I'm planning a trip and need some advice.\"),\n",
    "        (\"ai\", \"Sure, I'd be happy to help! What's your destination?\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "        (\"ai\", \"Great choice! I have some tips for {user_input}.\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(user_input=\"Paris\")\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abb1ddb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:34:29.096411Z",
     "iopub.status.busy": "2024-07-02T21:34:29.095444Z",
     "iopub.status.idle": "2024-07-02T21:34:29.100139Z",
     "shell.execute_reply": "2024-07-02T21:34:29.099161Z"
    },
    "id": "KYDJ1Mw-YjJ-",
    "outputId": "390b3c6b-0025-4006-fde9-6bd84997e036",
    "papermill": {
     "duration": 0.036688,
     "end_time": "2024-07-02T21:34:29.102355",
     "exception": false,
     "start_time": "2024-07-02T21:34:29.065667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# chat = ChatOpenAI(temperature=.7, model='gpt-3.5-turbo')\n",
    "\n",
    "# chat(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac57bd8",
   "metadata": {
    "id": "blYwXZfyYmlp",
    "papermill": {
     "duration": 0.027966,
     "end_time": "2024-07-02T21:34:29.158648",
     "exception": false,
     "start_time": "2024-07-02T21:34:29.130682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- The chat template sets up a conversation where the AI is a travel advisor.\n",
    "\n",
    "- The conversation starts with a human asking for travel advice, to which the AI responds by asking for the destination.\n",
    "\n",
    "- The user’s input is dynamically inserted into the conversation using {user_input}.\n",
    "\n",
    "- Finally, the AI provides tailored advice based on the user’s input, in this case, travel tips for Paris."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89572db",
   "metadata": {
    "id": "OX0V6IZQYsoz",
    "papermill": {
     "duration": 0.02884,
     "end_time": "2024-07-02T21:34:29.216557",
     "exception": false,
     "start_time": "2024-07-02T21:34:29.187717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Additionally, ChatPromptTemplate can be created with a list of messages.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "977f9afd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:34:29.276310Z",
     "iopub.status.busy": "2024-07-02T21:34:29.275255Z",
     "iopub.status.idle": "2024-07-02T21:34:29.284307Z",
     "shell.execute_reply": "2024-07-02T21:34:29.283337Z"
    },
    "id": "UEpowDYDY5eW",
    "papermill": {
     "duration": 0.041395,
     "end_time": "2024-07-02T21:34:29.286562",
     "exception": false,
     "start_time": "2024-07-02T21:34:29.245167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are an AI fitness advisor. You provide personalized workout and nutrition tips.'),\n",
       " HumanMessage(content='I need some advice about running a marathon.')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"You are an AI fitness advisor. You provide personalized workout and nutrition tips.\"\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"I need some advice about {topic}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(topic=\"running a marathon\")\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e90f4428",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:34:29.345114Z",
     "iopub.status.busy": "2024-07-02T21:34:29.344724Z",
     "iopub.status.idle": "2024-07-02T21:34:43.797235Z",
     "shell.execute_reply": "2024-07-02T21:34:43.795818Z"
    },
    "id": "LBDBFi8VAJDE",
    "outputId": "361e3d32-cc10-4c42-fba2-6a1c10ff7a4e",
    "papermill": {
     "duration": 14.485578,
     "end_time": "2024-07-02T21:34:43.800219",
     "exception": false,
     "start_time": "2024-07-02T21:34:29.314641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (4.12.2)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4) (2.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1566dcab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:34:43.861223Z",
     "iopub.status.busy": "2024-07-02T21:34:43.860404Z",
     "iopub.status.idle": "2024-07-02T21:35:03.868926Z",
     "shell.execute_reply": "2024-07-02T21:35:03.867808Z"
    },
    "papermill": {
     "duration": 20.041294,
     "end_time": "2024-07-02T21:35:03.871437",
     "exception": false,
     "start_time": "2024-07-02T21:34:43.830143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 21:34:49.485949: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-02 21:34:49.486071: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-02 21:34:49.609948: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Load documents from the web\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76459538",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:35:03.932462Z",
     "iopub.status.busy": "2024-07-02T21:35:03.932049Z",
     "iopub.status.idle": "2024-07-02T21:35:45.950313Z",
     "shell.execute_reply": "2024-07-02T21:35:45.949241Z"
    },
    "papermill": {
     "duration": 42.051414,
     "end_time": "2024-07-02T21:35:45.953003",
     "exception": false,
     "start_time": "2024-07-02T21:35:03.901589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9093fa7e0945dbb1dd40b3c49d7513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12aeeddf6c4b4e60a68c0e94a1ec2eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5311c28f69948bd8ea8d65614a3666c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b0fc38b30f4a0eb09d46abdcc0bbdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea56ecec85440d6aaaca5c411d36b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 100, but your input_length is only 83. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=41)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the summarization pipeline with a specified model\n",
    "model_name = \"sshleifer/distilbart-cnn-12-6\"\n",
    "summarizer = pipeline(\"summarization\", model=model_name)\n",
    "\n",
    "def chunk_text(text, max_length):\n",
    "    \"\"\"Split text into chunks of specified maximum length.\"\"\"\n",
    "    return [text[i:i+max_length] for i in range(0, len(text), max_length)]\n",
    "\n",
    "# Summarize each document's content\n",
    "for doc in docs:\n",
    "    # Assuming 'page_content' is the correct attribute to access the document's text\n",
    "    content = doc.page_content\n",
    "    \n",
    "    # Define the maximum length the model can handle\n",
    "    max_input_length = 1024\n",
    "    \n",
    "    # Split the content into manageable chunks\n",
    "    chunks = chunk_text(content, max_input_length)\n",
    "    \n",
    "    # Summarize each chunk\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        summary = summarizer(chunk, max_length=100, min_length=25, do_sample=False)\n",
    "        summaries.append(summary[0]['summary_text'])\n",
    "    \n",
    "    # Combine the summaries\n",
    "    combined_summary = \" \".join(summaries)\n",
    "    \n",
    "    combined_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d06b78e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:35:46.015418Z",
     "iopub.status.busy": "2024-07-02T21:35:46.014972Z",
     "iopub.status.idle": "2024-07-02T21:36:19.090773Z",
     "shell.execute_reply": "2024-07-02T21:36:19.089661Z"
    },
    "papermill": {
     "duration": 33.110107,
     "end_time": "2024-07-02T21:36:19.093523",
     "exception": false,
     "start_time": "2024-07-02T21:35:45.983416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 100, but your input_length is only 94. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=47)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LangSmith is a platform for LLM application development, monitoring, and testing . In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle .  LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues . We provide native rendering of chat messages, functions and retrieve documents .  LangSmith provides a playground environment for rapid iteration and experimentation . Beta testing allows developers to collect more data on how their LLM applications are performing in real-world scenarios .  LangSmith allows you to attach feedback scores to logged traces . This will help in curation of test cases that can help track regressions/improvements . LangSmith also supports sending runs to annotation queues, which allow annotators to inspect interesting traces .  LangSmith enables you to add runs as examples to datasets . This allows users to catch regressions across important evaluation criteria . LangSmith is a key benefit in having your logging system and your evaluation system in the same platform .  LangSmith provides monitoring charts that allow you to track key metrics over time . Automation allows you to perform actions on traces in near real-time . It also allows for tag and metadata grouping, which allows users to mark different versions of applications .  LangSmith provides a threads view that groups traces from a single conversation together . Automations are particularly helpful for processing traces at production scale .\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import pipeline\n",
    "\n",
    "# URL of the webpage to fetch\n",
    "url = \"https://docs.smith.langchain.com/user_guide\"\n",
    "\n",
    "# Fetch the content from the URL\n",
    "response = requests.get(url)\n",
    "web_content = response.content\n",
    "\n",
    "# Parse the content with BeautifulSoup\n",
    "soup = BeautifulSoup(web_content, 'html.parser')\n",
    "\n",
    "# Extract the main content you are interested in (this might vary depending on the website's structure)\n",
    "# Here, we assume the content is within <p> tags for simplicity\n",
    "content = \" \".join([p.get_text() for p in soup.find_all('p')])\n",
    "\n",
    "# Initialize the summarization pipeline with a specified model\n",
    "model_name = \"sshleifer/distilbart-cnn-12-6\"\n",
    "summarizer = pipeline(\"summarization\", model=model_name)\n",
    "\n",
    "def chunk_text(text, max_length):\n",
    "    \"\"\"Split text into chunks of specified maximum length.\"\"\"\n",
    "    return [text[i:i+max_length] for i in range(0, len(text), max_length)]\n",
    "\n",
    "# Define the maximum length the model can handle\n",
    "max_input_length = 1024\n",
    "\n",
    "# Split the content into manageable chunks\n",
    "chunks = chunk_text(content, max_input_length)\n",
    "\n",
    "# Summarize each chunk\n",
    "summaries = []\n",
    "for chunk in chunks:\n",
    "    summary = summarizer(chunk, max_length=100, min_length=25, do_sample=False)\n",
    "    summaries.append(summary[0]['summary_text'])\n",
    "\n",
    "# Combine the summaries\n",
    "combined_summary = \" \".join(summaries)\n",
    "\n",
    "# Print the combined summary\n",
    "print(combined_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96bc8a9",
   "metadata": {
    "papermill": {
     "duration": 0.030257,
     "end_time": "2024-07-02T21:36:19.154900",
     "exception": false,
     "start_time": "2024-07-02T21:36:19.124643",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"position: relative; text-align: center; background-image: url('https://th.bing.com/th/id/OIP.FhY2jL9E3OtyWAmmT_fFaAHaDt?w=341&h=175&c=7&r=0&o=5&dpr=1.5&pid=1.7'); background-size: 50%; background-position: center; border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n",
    "    <div style=\"position: relative; z-index: 1; background-color: rgba(255, 255, 255, 0.9); backdrop-filter: blur(10px); border-radius: 20px; padding: 20px;\">\n",
    "        WebBaseLoader vs BeautifulSoup\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729fb760",
   "metadata": {
    "papermill": {
     "duration": 0.031224,
     "end_time": "2024-07-02T21:36:19.217001",
     "exception": false,
     "start_time": "2024-07-02T21:36:19.185777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "### Loading Method\n",
    "\n",
    "- **WebBaseLoader**: Uses the `langchain_community.document_loaders.WebBaseLoader` to load and preprocess the documents.\n",
    "- **BeautifulSoup**: Uses `requests` to fetch the raw HTML and `BeautifulSoup` to parse and extract text content.\n",
    "\n",
    "### Content Extraction\n",
    "\n",
    "- **WebBaseLoader**: Automatically processes the web content and provides the document text through its API.\n",
    "- **BeautifulSoup**: Manually extracts text from specific HTML tags (e.g., `<p>`) based on the structure of the webpage.\n",
    "\n",
    "### Dependency\n",
    "\n",
    "- **WebBaseLoader**: Relies on the `langchain_community` library.\n",
    "- **BeautifulSoup**: Relies on the `requests` and `beautifulsoup4` libraries.\n",
    "\n",
    "### Flexibility\n",
    "\n",
    "- **WebBaseLoader**: Less control over how content is extracted; it abstracts away many details.\n",
    "- **BeautifulSoup**: More control and flexibility in parsing and extracting specific parts of the webpage content.\n",
    "\n",
    "## When to Use Which\n",
    "\n",
    "- **WebBaseLoader**: Suitable for quick, high-level content loading without needing to manually handle HTML parsing. Ideal if the webpage structure is consistent and supported by the loader.\n",
    "- **BeautifulSoup**: Preferred when you need fine-grained control over the content extraction process, or if the webpage has a complex structure that requires custom parsing logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c13033ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:36:19.279273Z",
     "iopub.status.busy": "2024-07-02T21:36:19.278855Z",
     "iopub.status.idle": "2024-07-02T21:36:19.284188Z",
     "shell.execute_reply": "2024-07-02T21:36:19.283079Z"
    },
    "id": "CEyJHhggAyJw",
    "papermill": {
     "duration": 0.039048,
     "end_time": "2024-07-02T21:36:19.286527",
     "exception": false,
     "start_time": "2024-07-02T21:36:19.247479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you wants to run this cell then you need OpenAI API key \n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# embeddings = OpenAIEmbeddings(openai_api_key=openai_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03089eed",
   "metadata": {
    "papermill": {
     "duration": 0.029982,
     "end_time": "2024-07-02T21:36:19.346922",
     "exception": false,
     "start_time": "2024-07-02T21:36:19.316940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"position: relative; text-align: center; background-image: url('https://th.bing.com/th/id/OIP.FhY2jL9E3OtyWAmmT_fFaAHaDt?w=341&h=175&c=7&r=0&o=5&dpr=1.5&pid=1.7'); background-size: 50%; background-position: center; border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n",
    "    <div style=\"position: relative; z-index: 1; background-color: rgba(255, 255, 255, 0.9); backdrop-filter: blur(10px); border-radius: 20px; padding: 20px;\">\n",
    "            FAISS (Facebook AI Similarity Search)\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9453c3c1",
   "metadata": {
    "papermill": {
     "duration": 0.030472,
     "end_time": "2024-07-02T21:36:19.407858",
     "exception": false,
     "start_time": "2024-07-02T21:36:19.377386",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "FAISS is a library developed by Facebook AI Research designed for efficient similarity search and clustering of high-dimensional vectors. It excels in handling large-scale data and is useful for:\n",
    "\n",
    "- **Searching for Similar Items**: Quickly finding vectors (representing items like text or images) similar to a given query vector.\n",
    "- **Clustering**: Grouping vectors into clusters to identify patterns or organize data.\n",
    "\n",
    "### Embeddings\n",
    "\n",
    "Embeddings are dense numerical representations of data that capture its essence or features. Examples include:\n",
    "\n",
    "- **Text Embeddings**: Convert words or sentences into vectors using models like Word2Vec, GloVe, BERT, or GPT.\n",
    "- **Image Embeddings**: Represent images as vectors, typically using models such as ResNet or VGG.\n",
    "\n",
    "### How FAISS and Embeddings Work Together\n",
    "\n",
    "1. **Generate Embeddings**: Convert data (text, images, etc.) into vectors using a model.\n",
    "2. **Indexing with FAISS**: Store these vectors in a FAISS index for fast querying.\n",
    "3. **Searching**: Convert a query into an embedding and use FAISS to find and retrieve similar vectors from the index.\n",
    "\n",
    "### LangChain and FAISS\n",
    "\n",
    "- **LangChain**: A framework for building applications with large language models (LLMs).\n",
    "- **FAISS Integration**: Used within LangChain to manage and search embeddings generated by LLMs, enabling tasks like semantic search and document retrieval.\n",
    "\n",
    "In summary, FAISS efficiently manages and searches large sets of vector embeddings, essential for applications processing high-dimensional data quickly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f1ab7de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:36:19.469508Z",
     "iopub.status.busy": "2024-07-02T21:36:19.469152Z",
     "iopub.status.idle": "2024-07-02T21:36:35.570288Z",
     "shell.execute_reply": "2024-07-02T21:36:35.568977Z"
    },
    "id": "pfy82m9wBaaq",
    "outputId": "3da02cec-1696-4d5e-81d3-514cb276967d",
    "papermill": {
     "duration": 16.13526,
     "end_time": "2024-07-02T21:36:35.573268",
     "exception": false,
     "start_time": "2024-07-02T21:36:19.438008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\r\n",
      "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from faiss-cpu) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from faiss-cpu) (24.1)\r\n",
      "Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\r\n",
      "Successfully installed faiss-cpu-1.8.0.post1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77e4b4a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:36:35.639507Z",
     "iopub.status.busy": "2024-07-02T21:36:35.639075Z",
     "iopub.status.idle": "2024-07-02T21:36:35.667921Z",
     "shell.execute_reply": "2024-07-02T21:36:35.666230Z"
    },
    "id": "9Vz3ymRnBg5P",
    "papermill": {
     "duration": 0.064996,
     "end_time": "2024-07-02T21:36:35.670431",
     "exception": false,
     "start_time": "2024-07-02T21:36:35.605435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='LangSmith User Guide | 🦜️🛠️ LangSmith', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}), Document(page_content='Skip to main contentGo to API DocsSearchGo to AppQuick StartUser GuideTracingEvaluationProduction Monitoring & AutomationsPrompt HubProxyPricingSelf-HostingCookbookThis is outdated documentation for 🦜️🛠️ LangSmith, which is no longer actively maintained.For up-to-date documentation, see the latest version.User GuideOn this pageLangSmith User GuideLangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.Prototyping\\u200bPrototyping LLM applications often involves quick experimentation between prompts, model types, retrieval strategy and other parameters.\\nThe ability to rapidly understand how the model is performing — and debug where it is failing — is incredibly important for this phase.Debugging\\u200bWhen developing new LLM applications, we suggest having LangSmith tracing enabled by default.\\nOftentimes, it isn’t necessary to look at every single trace. However, when things go wrong (an unexpected end result, infinite agent loop, slower than expected execution, higher than expected token usage), it’s extremely helpful to debug by looking through the application traces. LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues.\\nWe provide native rendering of chat messages, functions, and retrieve documents.Initial Test Set\\u200bWhile many developers still ship an initial version of their application based on “vibe checks”, we’ve seen an increasing number of engineering teams start to adopt a more test driven approach. LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications.\\nThese test cases can be uploaded in bulk, created on the fly, or exported from application traces. LangSmith also makes it easy to run custom evaluations (both LLM and heuristic based) to score test results.Comparison View\\u200bWhen prototyping different versions of your applications and making changes, it’s important to see whether or not you’ve regressed with respect to your initial test cases.\\nOftentimes, changes in the prompt, retrieval strategy, or model choice can have huge implications in responses produced by your application.\\nIn order to get a sense for which variant is performing better, it’s useful to be able to view results for different configurations on the same datapoints side-by-side. We’ve invested heavily in a user-friendly comparison view for test runs to track and diagnose regressions in test scores across multiple revisions of your application.Playground\\u200bLangSmith provides a playground environment for rapid iteration and experimentation.\\nThis allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}), Document(page_content=\"Every playground run is logged in the system and can be used to create test cases or compare with other runs.Beta Testing\\u200bBeta testing allows developers to collect more data on how their LLM applications are performing in real-world scenarios. In this phase, it’s important to develop an understanding for the types of inputs the app is performing well or poorly on and how exactly it’s breaking down in those cases. Both feedback collection and run annotation are critical for this workflow. This will help in curation of test cases that can help track regressions/improvements and development of automatic evaluations.Capturing Feedback\\u200bWhen launching your application to an initial set of users, it’s important to gather human feedback on the responses it’s producing. This helps draw attention to the most interesting runs and highlight edge cases that are causing problematic responses. LangSmith allows you to attach feedback scores to logged traces (oftentimes, this is hooked up to a feedback button in your app), then filter on traces that have a specific feedback tag and score. A common workflow is to filter on traces that receive a poor user feedback score, then drill down into problematic points using the detailed trace view.Annotating Traces\\u200bLangSmith also supports sending runs to annotation queues, which allow annotators to closely inspect interesting traces and annotate them with respect to different criteria. Annotators can be PMs, engineers, or even subject matter experts. This allows users to catch regressions across important evaluation criteria.Adding Runs to a Dataset\\u200bAs your application progresses through the beta testing phase, it's essential to continue collecting data to refine and improve its performance. LangSmith enables you to add runs as examples to datasets (from both the project page and within an annotation queue), expanding your test coverage on real-world scenarios. This is a key benefit in having your logging system and your evaluation/testing system in the same platform.Production\\u200bClosely inspecting key data points, growing benchmarking datasets, annotating traces, and drilling down into important data in trace view are workflows you’ll also want to do once your app hits production.However, especially at the production stage, it’s crucial to get a high-level overview of application performance with respect to latency, cost, and feedback scores. This ensures that it's delivering desirable results at scale.Online evaluations and automations allow you to process and score production traces in near real-time.Additionally, threads provide a seamless way to group traces from a single conversation, making it easier to track the performance of your application across multiple turns.Monitoring and A/B Testing\\u200bLangSmith provides monitoring charts that allow you to track key metrics over time. You can expand to view metrics for a given period and drill down into a specific data point to get a trace table for that time period — this is especially handy for debugging production issues.LangSmith also allows for tag and metadata grouping, which allows users to mark different versions of their applications with different identifiers and view how they are performing side-by-side within each chart. This is helpful for A/B testing changes in prompt, model, or retrieval strategy.Automations\\u200bAutomations are a powerful feature in LangSmith that allow you to perform actions on traces in near real-time. This can be used to automatically score traces, send them to annotation queues, or send them to datasets.To define an automation, simply provide a filter condition, a sampling rate, and an action to perform. Automations are particularly helpful for processing traces at production scale.Threads\\u200bMany LLM applications are multi-turn, meaning that they involve a series of interactions between the user and the application. LangSmith provides a threads view that groups traces from a single conversation together, making it easier to\", metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}), Document(page_content='meaning that they involve a series of interactions between the user and the application. LangSmith provides a threads view that groups traces from a single conversation together, making it easier to track the performance of and annotate your application across multiple turns.Was this page helpful?You can leave detailed feedback on GitHub.PreviousQuick StartNextOverviewPrototypingBeta TestingProductionCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "print(documents)\n",
    "# vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf4d28d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:36:35.736897Z",
     "iopub.status.busy": "2024-07-02T21:36:35.736447Z",
     "iopub.status.idle": "2024-07-02T21:36:35.743679Z",
     "shell.execute_reply": "2024-07-02T21:36:35.742634Z"
    },
    "id": "kaLBCBlrD7tV",
    "outputId": "e464c017-a0c2-4024-a95c-2d8ed07b921b",
    "papermill": {
     "duration": 0.042415,
     "end_time": "2024-07-02T21:36:35.745834",
     "exception": false,
     "start_time": "2024-07-02T21:36:35.703419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd3dbbdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:36:35.813970Z",
     "iopub.status.busy": "2024-07-02T21:36:35.813521Z",
     "iopub.status.idle": "2024-07-02T21:36:35.820750Z",
     "shell.execute_reply": "2024-07-02T21:36:35.819769Z"
    },
    "id": "CZWZCeaJEGgR",
    "outputId": "2029477a-c6f0-4562-b8e0-6288d1e74e18",
    "papermill": {
     "duration": 0.044983,
     "end_time": "2024-07-02T21:36:35.823037",
     "exception": false,
     "start_time": "2024-07-02T21:36:35.778054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='meaning that they involve a series of interactions between the user and the application. LangSmith provides a threads view that groups traces from a single conversation together, making it easier to track the performance of and annotate your application across multiple turns.Was this page helpful?You can leave detailed feedback on GitHub.PreviousQuick StartNextOverviewPrototypingBeta TestingProductionCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "461c7934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:36:35.887717Z",
     "iopub.status.busy": "2024-07-02T21:36:35.887322Z",
     "iopub.status.idle": "2024-07-02T21:36:35.892016Z",
     "shell.execute_reply": "2024-07-02T21:36:35.891033Z"
    },
    "id": "jdr8JSCMEbk0",
    "papermill": {
     "duration": 0.039674,
     "end_time": "2024-07-02T21:36:35.894224",
     "exception": false,
     "start_time": "2024-07-02T21:36:35.854550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "# <context>\n",
    "# {context}\n",
    "# </context>\n",
    "\n",
    "# Question: {input}\"\"\")\n",
    "\n",
    "# document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4a0681d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:36:35.960220Z",
     "iopub.status.busy": "2024-07-02T21:36:35.959194Z",
     "iopub.status.idle": "2024-07-02T21:36:35.964230Z",
     "shell.execute_reply": "2024-07-02T21:36:35.963157Z"
    },
    "id": "XJTrGHYZEjqR",
    "outputId": "9cc0b126-e525-459a-9fde-7c6635b1466b",
    "papermill": {
     "duration": 0.041017,
     "end_time": "2024-07-02T21:36:35.966808",
     "exception": false,
     "start_time": "2024-07-02T21:36:35.925791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain_core.documents import Document\n",
    "\n",
    "# document_chain.invoke({\n",
    "#     \"input\": \"how can langsmith help with testing?\",\n",
    "#     \"context\": [Document(page_content=\"langsmith can let you visualize test results\")]\n",
    "# })\n",
    "\n",
    "# Output\n",
    "# \\n\\nAnswer: Langsmith can help by allowing you to visualize test results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d819ef8",
   "metadata": {
    "papermill": {
     "duration": 0.031638,
     "end_time": "2024-07-02T21:36:36.030751",
     "exception": false,
     "start_time": "2024-07-02T21:36:35.999113",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Answer:- \n",
    "LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications. These test cases can be uploaded in bulk, created on the fly, or exported from application traces. \n",
    "\n",
    "LangSmith also makes it easy to run custom evaluations (both LLM and heuristic based) to score test results. Additionally, LangSmith provides a playground environment for rapid iteration and experimentation, as well as the ability to compare different versions of the application to track and diagnose any regressions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4d42dcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:36:36.096911Z",
     "iopub.status.busy": "2024-07-02T21:36:36.096476Z",
     "iopub.status.idle": "2024-07-02T21:36:36.101119Z",
     "shell.execute_reply": "2024-07-02T21:36:36.100100Z"
    },
    "id": "fC51knI6E0Sw",
    "papermill": {
     "duration": 0.040583,
     "end_time": "2024-07-02T21:36:36.103315",
     "exception": false,
     "start_time": "2024-07-02T21:36:36.062732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain.chains import create_retrieval_chain\n",
    "\n",
    "# retriever = vector.as_retriever()\n",
    "# retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54466eaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:36:36.168508Z",
     "iopub.status.busy": "2024-07-02T21:36:36.168084Z",
     "iopub.status.idle": "2024-07-02T21:36:36.172943Z",
     "shell.execute_reply": "2024-07-02T21:36:36.171938Z"
    },
    "id": "CgJHzQffE705",
    "outputId": "93fb159a-c783-46a5-d4be-1ba19046b968",
    "papermill": {
     "duration": 0.039683,
     "end_time": "2024-07-02T21:36:36.175069",
     "exception": false,
     "start_time": "2024-07-02T21:36:36.135386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "# print(response[\"answer\"])\n",
    "\n",
    "# # LangSmith offers several features that can help with testing:..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86027d5",
   "metadata": {
    "id": "_BmXodXjNcSj",
    "papermill": {
     "duration": 0.032505,
     "end_time": "2024-07-02T21:36:36.239731",
     "exception": false,
     "start_time": "2024-07-02T21:36:36.207226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"position: relative; text-align: center; background-image: url('https://th.bing.com/th/id/OIP.FhY2jL9E3OtyWAmmT_fFaAHaDt?w=341&h=175&c=7&r=0&o=5&dpr=1.5&pid=1.7'); background-size: 50%; background-position: center; border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n",
    "    <div style=\"position: relative; z-index: 1; background-color: rgba(255, 255, 255, 0.9); backdrop-filter: blur(10px); border-radius: 20px; padding: 20px;\">\n",
    "        ConversationalRetrievalChain\n",
    "    </div>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e18a44",
   "metadata": {
    "id": "fE0wPAbzObAc",
    "papermill": {
     "duration": 0.032072,
     "end_time": "2024-07-02T21:36:36.304766",
     "exception": false,
     "start_time": "2024-07-02T21:36:36.272694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The chain we've created so far can only answer single questions. One of the main types of LLM applications that people are building are chat bots. So how do we turn this chain into one that can answer follow up questions?\n",
    "\n",
    "We can still use the create_retrieval_chain function, but we need to change two things:\n",
    "\n",
    "The retrieval method should now not just work on the most recent input, but rather should take the whole history into account.\n",
    "The final LLM chain should likewise take the whole history into account\n",
    "Updating Retrieval\n",
    "\n",
    "In order to update retrieval, we will create a new chain. This chain will take in the most recent input (input) and the conversation history (chat_history) and use an LLM to generate a search query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f771ce43",
   "metadata": {
    "papermill": {
     "duration": 0.030808,
     "end_time": "2024-07-02T21:36:36.368450",
     "exception": false,
     "start_time": "2024-07-02T21:36:36.337642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"position: relative; text-align: center; background-image: url('https://th.bing.com/th/id/OIP.FhY2jL9E3OtyWAmmT_fFaAHaDt?w=341&h=175&c=7&r=0&o=5&dpr=1.5&pid=1.7'); background-size: 50%; background-position: center; border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n",
    "    <div style=\"position: relative; z-index: 1; background-color: rgba(255, 255, 255, 0.9); backdrop-filter: blur(10px); border-radius: 20px; padding: 20px;\">\n",
    "        Intelligent Context-Sensitive Information Retrieval System\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa14dda",
   "metadata": {
    "papermill": {
     "duration": 0.03124,
     "end_time": "2024-07-02T21:36:36.431217",
     "exception": false,
     "start_time": "2024-07-02T21:36:36.399977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "This system integrates a language model with a document retrieval and processing workflow to create an intelligent, context-sensitive information retrieval and response system.\n",
    "\n",
    "## Components\n",
    "\n",
    "1. **Text Splitting and Vectorization**\n",
    "   - **Text Splitting**: Use `RecursiveCharacterTextSplitter` to divide text into manageable chunks.\n",
    "   - **Vectorization**: Apply `FAISS` to create a vector store from these chunks, enabling efficient similarity searches.\n",
    "\n",
    "2. **Retriever Setup**\n",
    "   - **Retriever Initialization**: Use `vector.as_retriever()` to set up a retriever that fetches relevant documents based on the vector store.\n",
    "\n",
    "3. **Prompt and Retrieval Chain**\n",
    "   - **Prompt Template**: Define a prompt template (`ChatPromptTemplate`) to guide the language model (LLM) in generating a search query based on conversation history.\n",
    "   - **Context-Aware Retriever**: Integrate this prompt with the retriever using `create_history_aware_retriever` to create a chain that considers chat history for generating queries.\n",
    "\n",
    "4. **Document Retrieval and Answering**\n",
    "   - **Document Retrieval Chain**: Use `create_stuff_documents_chain` to answer user questions based on the retrieved documents and context.\n",
    "   - **Complete Retrieval Chain**: Combine the retrieval chain and document chain using `create_retrieval_chain` to form a comprehensive system that processes user queries with context-aware information retrieval.\n",
    "\n",
    "5. **Example Query**\n",
    "   - **Demonstration**: Illustrate how the system responds to a query using sample chat history to show the effectiveness of the context-aware retrieval and response system.\n",
    "\n",
    "## Summary\n",
    "\n",
    "1. **Split Text and Create Vector Store**\n",
    "   - Break text into smaller chunks.\n",
    "   - Convert these chunks into vectors for efficient searching.\n",
    "\n",
    "2. **Setup for Document Retrieval**\n",
    "   - Utilize vectors to find relevant documents when needed.\n",
    "\n",
    "3. **Create a Query Generation System**\n",
    "   - Develop a template for the LLM to generate search queries based on conversation history.\n",
    "\n",
    "4. **Combine Retrieval and Document Answering**\n",
    "   - Establish a system that retrieves relevant documents first, then answers questions based on those documents.\n",
    "\n",
    "5. **Example Usage**\n",
    "   - Demonstrate how the system answers a question using previous chat history and retrieved documents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9132b0dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:36:36.495414Z",
     "iopub.status.busy": "2024-07-02T21:36:36.494617Z",
     "iopub.status.idle": "2024-07-02T21:36:36.596237Z",
     "shell.execute_reply": "2024-07-02T21:36:36.595118Z"
    },
    "id": "4E3yI01kNscS",
    "outputId": "a99f3882-56ed-4785-cc78-2809f0b2f36e",
    "papermill": {
     "duration": 0.136258,
     "end_time": "2024-07-02T21:36:36.598705",
     "exception": false,
     "start_time": "2024-07-02T21:36:36.462447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "docs = loader.load()\n",
    "print(type(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7d08d1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:36:36.664140Z",
     "iopub.status.busy": "2024-07-02T21:36:36.663747Z",
     "iopub.status.idle": "2024-07-02T21:36:36.668743Z",
     "shell.execute_reply": "2024-07-02T21:36:36.667607Z"
    },
    "id": "34QEES8fOp1f",
    "papermill": {
     "duration": 0.039873,
     "end_time": "2024-07-02T21:36:36.671097",
     "exception": false,
     "start_time": "2024-07-02T21:36:36.631224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain_community.vectorstores import FAISS\n",
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter()\n",
    "# documents = text_splitter.split_documents(docs)\n",
    "# vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef36c29c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:36:36.738364Z",
     "iopub.status.busy": "2024-07-02T21:36:36.737442Z",
     "iopub.status.idle": "2024-07-02T21:36:36.742194Z",
     "shell.execute_reply": "2024-07-02T21:36:36.741145Z"
    },
    "id": "nNqeVRZsO4L3",
    "papermill": {
     "duration": 0.040591,
     "end_time": "2024-07-02T21:36:36.744397",
     "exception": false,
     "start_time": "2024-07-02T21:36:36.703806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "438e66d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:36:36.816215Z",
     "iopub.status.busy": "2024-07-02T21:36:36.815805Z",
     "iopub.status.idle": "2024-07-02T21:36:36.820823Z",
     "shell.execute_reply": "2024-07-02T21:36:36.819778Z"
    },
    "id": "KRIPF_PIRQjG",
    "papermill": {
     "duration": 0.045987,
     "end_time": "2024-07-02T21:36:36.823122",
     "exception": false,
     "start_time": "2024-07-02T21:36:36.777135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# llm = ChatOpenAI(api_key=openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ed4819d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:36:36.892306Z",
     "iopub.status.busy": "2024-07-02T21:36:36.891920Z",
     "iopub.status.idle": "2024-07-02T21:36:36.897443Z",
     "shell.execute_reply": "2024-07-02T21:36:36.896247Z"
    },
    "id": "r_1I1QEmOgYx",
    "papermill": {
     "duration": 0.045189,
     "end_time": "2024-07-02T21:36:36.900565",
     "exception": false,
     "start_time": "2024-07-02T21:36:36.855376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain.chains import create_history_aware_retriever\n",
    "# from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# # First we need a prompt that we can pass into an LLM to generate this search query\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "#     (\"user\", \"{input}\"),\n",
    "#     (\"user\", \"Given the above conversation, generate a search query to look up to get information relevant to the conversation\")\n",
    "# ])\n",
    "# retriever_chain = create_history_aware_retriever(llm, retriever, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ce98021",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:36:36.979241Z",
     "iopub.status.busy": "2024-07-02T21:36:36.978869Z",
     "iopub.status.idle": "2024-07-02T21:36:36.983286Z",
     "shell.execute_reply": "2024-07-02T21:36:36.982228Z"
    },
    "id": "JeChlhhTRl2B",
    "papermill": {
     "duration": 0.045255,
     "end_time": "2024-07-02T21:36:36.985613",
     "exception": false,
     "start_time": "2024-07-02T21:36:36.940358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retriever_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4cc3cd52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:36:37.051050Z",
     "iopub.status.busy": "2024-07-02T21:36:37.050130Z",
     "iopub.status.idle": "2024-07-02T21:36:37.054928Z",
     "shell.execute_reply": "2024-07-02T21:36:37.053922Z"
    },
    "id": "W3NIuoGLPP5X",
    "outputId": "4358f68a-395b-41bb-a949-e9bb7bd27bf4",
    "papermill": {
     "duration": 0.039504,
     "end_time": "2024-07-02T21:36:37.057180",
     "exception": false,
     "start_time": "2024-07-02T21:36:37.017676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "# print(retriever_chain.invoke({\n",
    "#     \"chat_history\": chat_history,\n",
    "#     \"input\": \"Tell me how in one word\"\n",
    "# }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77e21593",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:36:37.122249Z",
     "iopub.status.busy": "2024-07-02T21:36:37.121854Z",
     "iopub.status.idle": "2024-07-02T21:36:37.126351Z",
     "shell.execute_reply": "2024-07-02T21:36:37.125367Z"
    },
    "id": "JbEDCw4RSlWz",
    "papermill": {
     "duration": 0.039242,
     "end_time": "2024-07-02T21:36:37.128535",
     "exception": false,
     "start_time": "2024-07-02T21:36:37.089293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "# from langchain.chains import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd309a34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:36:37.193298Z",
     "iopub.status.busy": "2024-07-02T21:36:37.192870Z",
     "iopub.status.idle": "2024-07-02T21:36:37.197900Z",
     "shell.execute_reply": "2024-07-02T21:36:37.196653Z"
    },
    "id": "DaMH4f-1Sa7u",
    "papermill": {
     "duration": 0.040408,
     "end_time": "2024-07-02T21:36:37.200385",
     "exception": false,
     "start_time": "2024-07-02T21:36:37.159977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"Answer the user's questions based on the below context:\\n\\n{context}\"),\n",
    "#     MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "#     (\"user\", \"{input}\"),\n",
    "# ])\n",
    "# document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# retrieval_chain = create_retrieval_chain(retriever_chain, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "832f28fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:36:37.266929Z",
     "iopub.status.busy": "2024-07-02T21:36:37.266482Z",
     "iopub.status.idle": "2024-07-02T21:36:37.271302Z",
     "shell.execute_reply": "2024-07-02T21:36:37.270220Z"
    },
    "id": "nOmKu5ldSeww",
    "papermill": {
     "duration": 0.040606,
     "end_time": "2024-07-02T21:36:37.273403",
     "exception": false,
     "start_time": "2024-07-02T21:36:37.232797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "# retrieval_chain.invoke({\n",
    "#     \"chat_history\": chat_history,\n",
    "#     \"input\": \"Tell me how\"\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc745ada",
   "metadata": {
    "papermill": {
     "duration": 0.031932,
     "end_time": "2024-07-02T21:36:37.337896",
     "exception": false,
     "start_time": "2024-07-02T21:36:37.305964",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"position: relative; text-align: center; background-image: url('https://th.bing.com/th/id/OIP.FhY2jL9E3OtyWAmmT_fFaAHaDt?w=341&h=175&c=7&r=0&o=5&dpr=1.5&pid=1.7'); background-size: 50%; background-position: center; border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n",
    "    <div style=\"position: relative; z-index: 1; background-color: rgba(255, 255, 255, 0.9); backdrop-filter: blur(10px); border-radius: 20px; padding: 20px;\">\n",
    "        LangSmith Settings\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf4b573",
   "metadata": {
    "papermill": {
     "duration": 0.032115,
     "end_time": "2024-07-02T21:36:37.402476",
     "exception": false,
     "start_time": "2024-07-02T21:36:37.370361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "LangSmith Settings are configuration options in LangChain that manage and fine-tune language models for specific tasks and applications. They help customize and optimize these models to improve performance and meet specific requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75645e31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T21:36:37.468270Z",
     "iopub.status.busy": "2024-07-02T21:36:37.467263Z",
     "iopub.status.idle": "2024-07-02T21:36:37.474905Z",
     "shell.execute_reply": "2024-07-02T21:36:37.473776Z"
    },
    "papermill": {
     "duration": 0.043384,
     "end_time": "2024-07-02T21:36:37.477842",
     "exception": false,
     "start_time": "2024-07-02T21:36:37.434458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables set successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Lang Chain 1st Project\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "\n",
    "# Ensure the API key is set\n",
    "# You need to set this key manually if not already available\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"your_api_key_here\"  # Replace with your actual API key\n",
    "\n",
    "# Check if the API key is set correctly\n",
    "api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"LANGCHAIN_API_KEY is not set. Please set it before proceeding.\")\n",
    "\n",
    "print(\"Environment variables set successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d603c8",
   "metadata": {
    "papermill": {
     "duration": 0.03202,
     "end_time": "2024-07-02T21:36:37.542230",
     "exception": false,
     "start_time": "2024-07-02T21:36:37.510210",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"position: relative; text-align: center; background-image: url('https://th.bing.com/th/id/OIF.OQvVLEvcQ1B5sJYkwxlRcQ?w=218&h=183&c=7&r=0&o=5&dpr=1.5&pid=1.7'); background-size: cover; background-position: center; border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19);\">\n",
    "    <div style=\"position: relative; z-index: 1; background-color: rgba(255, 255, 255, 0.9); backdrop-filter: blur(10px); border-radius: 20px; padding: 20px;\">\n",
    "        <div style=\"border-radius: 20px; border: 2px solid #336699; padding: 20px; background-color: #e0f7fa; text-align: center; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19);\">\n",
    "            <h1 style=\"color: #003366; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.4); font-weight: bold; margin-bottom: 10px; font-size: 32px;\">\n",
    "                Thank You!\n",
    "            </h1>\n",
    "            <p style=\"color: #003366; font-size: 18px; margin: 15px 0;\">\n",
    "                Thank you so much for joining me on this journey through the world of Lgain chain Advance Project! Your support and enthusiasm have been incredibly motivating. 🌟\n",
    "            </p>\n",
    "            <blockquote style=\"border-left: 4px solid #336699; padding-left: 10px; color: #003366; font-size: 18px; margin: 20px 0; background-color: #f0f8ff; padding: 10px;\">\n",
    "                As I delve deeper into the realm of <strong>Generative AI</strong>, I am grateful for your continued encouragement and guidance. Together, we are pushing the boundaries of what's possible in data science and beyond. 🚀💡\n",
    "            </blockquote>\n",
    "          \n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 233.193471,
   "end_time": "2024-07-02T21:36:40.623248",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-02T21:32:47.429777",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "011520f1004e422392c85b8509275aaf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_528a5525ef7048adb952d3bde3bf5b95",
       "max": 456318.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_decbc03b15724485b8dbbffbd5cc1e32",
       "value": 456318.0
      }
     },
     "0938335299c24829a14a547b93d7f715": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0b0f8a50031046d19f0e06ce5fef4076": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d88f807b47eb444ea1de7e0048e07128",
       "placeholder": "​",
       "style": "IPY_MODEL_0caa8cf312ed47a89588001d87f6864e",
       "value": "config.json: 100%"
      }
     },
     "0caa8cf312ed47a89588001d87f6864e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0d4439350605497285a8a067024f0b4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_db0497cd23f44370a6cf6178fee1fb31",
       "placeholder": "​",
       "style": "IPY_MODEL_cf963a48f15b44878fd248c86569e056",
       "value": " 456k/456k [00:00&lt;00:00, 2.78MB/s]"
      }
     },
     "11909a2cdf7b49a3928e24250e813521": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e91b2a72a1774d8fa8cdf2385389ac4a",
       "placeholder": "​",
       "style": "IPY_MODEL_9a1504a1fd454c1698e499dd111e9755",
       "value": " 899k/899k [00:00&lt;00:00, 2.73MB/s]"
      }
     },
     "12aeeddf6c4b4e60a68c0e94a1ec2eea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b93dd46c200048a4991653e4f9d4e9a3",
        "IPY_MODEL_fdbe7c40d6d149ec8dce105f7f8a0d5f",
        "IPY_MODEL_2e3527668ea04865a800b2ad9605511e"
       ],
       "layout": "IPY_MODEL_19e34a57de0940fdb5dd1f72d1f8dd56"
      }
     },
     "19e34a57de0940fdb5dd1f72d1f8dd56": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1b1d604be25f47f1ad0773f42e43b16b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "200948ed45dd4dbb87a55c3dd63fa224": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ce237cc23d7d457997f833fa5a30467f",
       "placeholder": "​",
       "style": "IPY_MODEL_92ef017e602a4c998d02b8843887af89",
       "value": "vocab.json: 100%"
      }
     },
     "20c7f2fdb2af48d5b406e4bd7d7a5acc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0938335299c24829a14a547b93d7f715",
       "max": 898822.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5869714df3e84616860b0769da5687aa",
       "value": 898822.0
      }
     },
     "226d4ef246d64ee3a9ea9a58d590a34e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2b91d0ddda244b45bf28c1b7785d6acd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2e3527668ea04865a800b2ad9605511e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c10b0591c9aa4002b4c71917d2ef988d",
       "placeholder": "​",
       "style": "IPY_MODEL_cbc9de4633ab40d299f043aae4bd009a",
       "value": " 1.22G/1.22G [00:04&lt;00:00, 309MB/s]"
      }
     },
     "2e9093fa7e0945dbb1dd40b3c49d7513": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0b0f8a50031046d19f0e06ce5fef4076",
        "IPY_MODEL_5a80dbfb0bd64f5aa55659a2806ef6a3",
        "IPY_MODEL_fe388610522140769b5de41ca77d8cb1"
       ],
       "layout": "IPY_MODEL_58f5ff6bad2747f8a3c7943aadfdd4ef"
      }
     },
     "3f4656d3dee54622959e78cffd4911be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "43f21a80517b45b48519c2b9387eff4d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "528a5525ef7048adb952d3bde3bf5b95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "53b0fc38b30f4a0eb09d46abdcc0bbdf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_200948ed45dd4dbb87a55c3dd63fa224",
        "IPY_MODEL_20c7f2fdb2af48d5b406e4bd7d7a5acc",
        "IPY_MODEL_11909a2cdf7b49a3928e24250e813521"
       ],
       "layout": "IPY_MODEL_43f21a80517b45b48519c2b9387eff4d"
      }
     },
     "55f4210eb221492db6d012855778ba5a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "58002380054b4ba8a530d50fae58a64f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bb90309e30e948d6a826c425bb924c79",
       "placeholder": "​",
       "style": "IPY_MODEL_944784ea143a4c7b99533d9a37834bf2",
       "value": "tokenizer_config.json: 100%"
      }
     },
     "5869714df3e84616860b0769da5687aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "58f5ff6bad2747f8a3c7943aadfdd4ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5a80dbfb0bd64f5aa55659a2806ef6a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_55f4210eb221492db6d012855778ba5a",
       "max": 1802.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ffccbedf370743989a011fdf802bf023",
       "value": 1802.0
      }
     },
     "6ea56ecec85440d6aaaca5c411d36b77": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b084140d39044a659a2ca388d557b901",
        "IPY_MODEL_011520f1004e422392c85b8509275aaf",
        "IPY_MODEL_0d4439350605497285a8a067024f0b4c"
       ],
       "layout": "IPY_MODEL_a32a93622d3d4149b77b6e629aebd2ef"
      }
     },
     "92ef017e602a4c998d02b8843887af89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "944784ea143a4c7b99533d9a37834bf2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "97c69e3150a4452e9402f36d633a5149": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9925bb9dfc7a4c2480294fcbd7c513d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9a1504a1fd454c1698e499dd111e9755": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9adcffb0b6e94fbbb964d43d93773bac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_226d4ef246d64ee3a9ea9a58d590a34e",
       "placeholder": "​",
       "style": "IPY_MODEL_bf581de660d348e8969a935a73b2574e",
       "value": " 26.0/26.0 [00:00&lt;00:00, 1.87kB/s]"
      }
     },
     "a037513b68f240a684d6b449a5a93f4e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a1a51851697f459599a36cbfde42f655": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a32a93622d3d4149b77b6e629aebd2ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b084140d39044a659a2ca388d557b901": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a037513b68f240a684d6b449a5a93f4e",
       "placeholder": "​",
       "style": "IPY_MODEL_3f4656d3dee54622959e78cffd4911be",
       "value": "merges.txt: 100%"
      }
     },
     "b85f6801322743999430d31c21ebdb17": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9925bb9dfc7a4c2480294fcbd7c513d3",
       "max": 26.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ba363237803b44b99082b425a7805308",
       "value": 26.0
      }
     },
     "b86fd09efff049e5924a9f0ccd9eed77": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b93dd46c200048a4991653e4f9d4e9a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_97c69e3150a4452e9402f36d633a5149",
       "placeholder": "​",
       "style": "IPY_MODEL_a1a51851697f459599a36cbfde42f655",
       "value": "pytorch_model.bin: 100%"
      }
     },
     "ba363237803b44b99082b425a7805308": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bb90309e30e948d6a826c425bb924c79": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bf581de660d348e8969a935a73b2574e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c10b0591c9aa4002b4c71917d2ef988d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cbc9de4633ab40d299f043aae4bd009a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ce237cc23d7d457997f833fa5a30467f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cf963a48f15b44878fd248c86569e056": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d5311c28f69948bd8ea8d65614a3666c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_58002380054b4ba8a530d50fae58a64f",
        "IPY_MODEL_b85f6801322743999430d31c21ebdb17",
        "IPY_MODEL_9adcffb0b6e94fbbb964d43d93773bac"
       ],
       "layout": "IPY_MODEL_1b1d604be25f47f1ad0773f42e43b16b"
      }
     },
     "d88f807b47eb444ea1de7e0048e07128": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "db0497cd23f44370a6cf6178fee1fb31": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "decbc03b15724485b8dbbffbd5cc1e32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e91b2a72a1774d8fa8cdf2385389ac4a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fd29d454736f4aaf9ce95ee2b43a97d7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fdbe7c40d6d149ec8dce105f7f8a0d5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fd29d454736f4aaf9ce95ee2b43a97d7",
       "max": 1222317369.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fe86a79840954a41af60477c92fd75fa",
       "value": 1222317369.0
      }
     },
     "fe388610522140769b5de41ca77d8cb1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2b91d0ddda244b45bf28c1b7785d6acd",
       "placeholder": "​",
       "style": "IPY_MODEL_b86fd09efff049e5924a9f0ccd9eed77",
       "value": " 1.80k/1.80k [00:00&lt;00:00, 126kB/s]"
      }
     },
     "fe86a79840954a41af60477c92fd75fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ffccbedf370743989a011fdf802bf023": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
